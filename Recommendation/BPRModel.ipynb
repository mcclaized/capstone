{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Personalized Recommendation\n",
    "\n",
    "The code in this notebook defines the Bayesian Personalized Ranking model and shows how to train it on data in the format: (Target ISIN, Better Recommendation ISIN, Worse Recommendation ISIN).\n",
    "\n",
    "Please see BPRDataPreparation.ipynb for an example of how to bootstrap this model by creating training data from the outputs of a distance-based model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS FILE CONTAINS A MAPPING BETWEEN ISIN AND AN INDEX FOR THAT BOND THAT THE MODEL WILL USE TO IDENTIFY IT\n",
    "# e.g. {\"US00037BAB80\": 0, \"US00037BAC63\": 1, ...}\n",
    "isin_to_index_mapping_file = 'isin_to_index2.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A saved PyTorch Tensor that contains rows of (TARGET BOND INDEX, BETTER RECOMMENDATION INDEX, WORSE RECOMMENDATION INDEX)\n",
    "training_data_tensor = 'train/all_rankings.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: The PyTorch Tensor is faster, so load it first\n",
    "\n",
    "# A saved CSV that contains rows of (TARGET BOND ISIN, BETTER RECOMMENDATION ISIN, WORSE RECOMMENDATION ISIN)\n",
    "training_data_csv = 'train/all_rankings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from data import SingleDayDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPRModel(nn.Module):\n",
    "    \"\"\"\n",
    "    This class implements a PyTorch model for Bayesian Personalized Recommendation\n",
    "    Per https://arxiv.org/abs/1205.2618\n",
    "    \"\"\"\n",
    "    def __init__(self, num_bonds, num_factors, regularization_lambda=0.0000001):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.regularization_lambda = regularization_lambda\n",
    "        self.bond_embedding = nn.Embedding(num_bonds, num_factors)\n",
    "    \n",
    "    def forward(self, rankings):\n",
    "        # Input is a batch of (bond, better recommendation, worse recommendation) triplets\n",
    "        bonds = rankings[:,0]\n",
    "        better_recommendations = rankings[:,1]\n",
    "        worse_recommendations = rankings[:,2]\n",
    "        \n",
    "        # Fetch our existing latent vector representation of each bond\n",
    "        bond_embeddings = self.bond_embedding(bonds)\n",
    "        better_recommendation_embeddings = self.bond_embedding(better_recommendations)\n",
    "        worse_recommendation_embeddings = self.bond_embedding(worse_recommendations)\n",
    "        \n",
    "        # Compute the dot product of the latent embedding\n",
    "        # We equate large dot products with high bond similarity\n",
    "        dot_better = torch.sum(bond_embeddings * better_recommendation_embeddings, dim=1)\n",
    "        dot_worse = torch.sum(bond_embeddings * worse_recommendation_embeddings, dim=1)\n",
    "        dot_diff = dot_better - dot_worse\n",
    "        \n",
    "        log_likelihood = torch.mean(F.logsigmoid(dot_diff))\n",
    "        \n",
    "        # useful to track how many the model \"got right\", i.e. agrees that better ones are better\n",
    "        auc = torch.mean((dot_diff > 0).float())\n",
    "        \n",
    "        # Recall that a guassian prior is equivalent to l2 regularization\n",
    "        # http://bjlkeng.github.io/posts/probabilistic-interpretation-of-regularization/\n",
    "        prior = sum(\n",
    "            [\n",
    "                self.regularization_lambda * torch.sum(bond_embeddings * bond_embeddings),\n",
    "                lambda_item_bond * torch.sum(better_recommendation_embeddings * better_recommendation_embeddings),\n",
    "                lambda_item_bond * torch.sum(worse_recommendation_embeddings * worse_recommendation_embeddings),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return log_likelihood, prior, auc        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelHelper(object):\n",
    "    def __init__(self, model, isin_to_index_mapping, metadata):\n",
    "        \n",
    "        self.isin_to_index = isin_to_index_mapping\n",
    "        self.index_to_isin = {idx: isin for isin, idx in self.isin_to_index.items()}\n",
    "        \n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = model\n",
    "        self.metadata = metadata\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.005)\n",
    "        \n",
    "    def predict(self, isin, n=10):\n",
    "        with torch.no_grad():\n",
    "            bond_idx = self.isin_to_index[isin]\n",
    "            bond = self.model.bond_embedding(torch.tensor(bond_idx, device=self.device))\n",
    "            dots = torch.sum(bond * self.model.bond_embedding.weight.data, dim=1)\n",
    "            bond_indices = torch.argsort(dots, descending=True)[:n]\n",
    "            isins = [self.index_to_isin[i] for i in bond_indices.cpu().numpy().tolist()]\n",
    "            return isins\n",
    "    \n",
    "    def process_feedback(self, feedback):\n",
    "        # Save a list of [(bond, better recommendation, worse recommendation), ...]\n",
    "        feedback = [[self.isin_to_index[isin] for isin in isin_triplet] for isin_triplet in feedback]\n",
    "        feedback = torch.tensor(feedback, device=self.device)\n",
    "        likelihood, prior, auc = self.model(feedback)\n",
    "        loss = -likelihood + prior\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "    \n",
    "    def display(self, isins, display_cols=None):\n",
    "        if display_cols is None:\n",
    "            display_cols = ['BCLASS3', 'Ticker', 'Country', 'Bid Spread', 'Cur Yld', 'OAS', 'OAD', 'Cpn']\n",
    "        print(\n",
    "            tabulate(\n",
    "                self.metadata.get_bonds(isins)[display_cols], \n",
    "                headers=display_cols, \n",
    "                #showindex=\"never\"\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def save(self, path):\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "    \n",
    "    def load(self, path):\n",
    "        self.model.load_state_dict(torch.load(path))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadTensorDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Load the dataset from a saved tensor file on disk\n",
    "    \"\"\"\n",
    "    def __init__(self, tensor_file):\n",
    "        self.data = torch.load(tensor_file)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "num_factors = 32 # Number of latent factors, i.e we represent each bond as a 32 dimensional vector\n",
    "\n",
    "# Independent lambda regularization values \n",
    "# for user, items and bias.\n",
    "regularization_lambda = 0.0000001\n",
    "\n",
    "# Our initial learning rate \n",
    "lr = 0.0001\n",
    "\n",
    "# How many (u,i,j) triplets we sample for each batch\n",
    "samples = 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LoadTensorDataset(training_data_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isin_to_index_mapping = json.load(open(isin_to_index_mapping_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "dataloader = DataLoader(train_dataset, shuffle=True, num_workers=6, batch_size=samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bonds = len(isin_to_index_mapping)\n",
    "model = BPRModel(num_bonds, num_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load('models/bpr_v1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_helper = ModelHelper(model, isin_to_index_mapping, metadata=SingleDayDataLoader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bond = 'US539830AY52'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    exp_lr_scheduler.step()\n",
    "    for batch_idx, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        batch = batch.to(device)\n",
    "        likelihood, prior, auc = model(batch)\n",
    "        loss = -likelihood + prior\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if not batch_idx % 200:\n",
    "            print(\"Epoch: {}, Batch: {}, Loss: {}, AUC: {}\".format(epoch, batch_idx, loss, auc))\n",
    "        if not batch_idx % 500:\n",
    "            print(\"\\nTest bond:\")\n",
    "            model_helper.display([test_bond])\n",
    "            print(\"\\nSample predictions:\")\n",
    "            model_helper.display(\n",
    "                model_helper.predict(test_bond)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/bpr_v2.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporate user feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get existing predictions\n",
    "\n",
    "model_helper.display(\n",
    "    model_helper.predict(test_bond)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a pair that should be reorder\n",
    "\n",
    "model_helper.process_feedback([(test_bond, 'US92340LAC37', 'US565122AG31')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the new results! Note, you might have to run feedback a few times in order to have the desired effect\n",
    "\n",
    "model_helper.display(\n",
    "    model_helper.predict(test_bond)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
